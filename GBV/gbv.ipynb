{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a13ddabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f210c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        Had a dream i got raped last night. By a guy i...\n",
      "1        he thought the word raped means sex and told m...\n",
      "2        She NOT TALKING TO ME I WAS RAPED BY 2 MEN 1 M...\n",
      "3        I was sexually abused for 3 years at age 4 to ...\n",
      "4        Chessy Prout can do better by telling the trut...\n",
      "                               ...                        \n",
      "39645    ENTRY 1299: 21F. 23M, BF’s cousin. Got drunk o...\n",
      "39646    So you’re telling me Emmanuel Macron was groom...\n",
      "39647    My wife regularly beats me, I get dirty slaps ...\n",
      "39648    Me: Hey babe! Police officer boyfriend: is tha...\n",
      "39649    “I will take accountability if you think it’s ...\n",
      "Name: tweet, Length: 39650, dtype: object\n",
      "['Harmful_Traditional_practice' 'Physical_violence' 'economic_violence'\n",
      " 'emotional_violence' 'sexual_violence']\n"
     ]
    }
   ],
   "source": [
    "with ZipFile(\"gbv.zip\",\"r\") as zip:\n",
    "    zip.extractall()\n",
    "\n",
    "df = pd.read_csv(\"Train.csv\")\n",
    "print(df[\"tweet\"])\n",
    "print(unique_labels(df[\"type\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "184c8eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['had a dream i got raped last night by a guy i work with actually a guy i smoked with once at my house but he was doing too much tryna be sexual and it wasnt even like that for me just wanted to smoke', 'he thought the word raped means sex and told me i saw our dogs raping eachother and i was like wtf', 'she not talking to me i was raped by men molested he in jail on nother charge so she not saying word', 'i was sexually abused for years at age to no one believed me i was raped by my bros friend in a classroom at he was i told no one cause who would believe me my bro found out when i was his friend bragged to the wrong person it is hard to come forward', 'chessy prout can do better by telling the truth by not selling owen labrie out to hide whoever else dna was in her underwear she said i have never said he raped me that changed chessy to i was raped i was violated white female privilege allowed her a platform to lie']\n"
     ]
    }
   ],
   "source": [
    "def clean_text(x):\n",
    "    x = x.lower()\n",
    "    x = x.encode(\"ascii\",\"ignore\").decode()\n",
    "    x = re.sub(\"https*\\S+\",\" \",x)\n",
    "    x = re.sub(\"@\\S+\",\" \",x)\n",
    "    x = re.sub(\"#\\S+\",\" \",x)\n",
    "    x = re.sub(\"\\'\\w+\",\"\",x)\n",
    "    x = re.sub(\"[%s]\" % re.escape(string.punctuation),\" \",x)\n",
    "    x = re.sub(\"\\w*\\d+\\w*\",\"\",x)\n",
    "    x = re.sub(\"\\s{2,}\",\" \",x)\n",
    "    return x\n",
    "\n",
    "temp = []\n",
    "data_to_list = df[\"tweet\"]\n",
    "\n",
    "for i in range(len(data_to_list)):\n",
    "    temp.append(clean_text(data_to_list[i]))\n",
    "\n",
    "def tokenize(y):\n",
    "    for x in y:\n",
    "        yield(word_tokenize(str(x)))\n",
    "\n",
    "data_words = list(tokenize(temp))\n",
    "\n",
    "def detokenize(txt):\n",
    "    return TreebankWordDetokenizer().detokenize(txt)\n",
    "\n",
    "final_data = []\n",
    "for i in range(len(data_words)):\n",
    "    final_data.append(detokenize(data_words[i]))\n",
    "\n",
    "print(final_data[:5])\n",
    "final_data = np.array(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b349bc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bda043f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ...  182    4 1921]\n",
      " [   0    0    0 ...    9   34  559]\n",
      " [   0    0    0 ...   24  108  480]\n",
      " ...\n",
      " [   0    0    0 ...   32  166  126]\n",
      " [   0    0    0 ... 1673  203  190]\n",
      " [   0    0    0 ...  117   77  312]]\n"
     ]
    }
   ],
   "source": [
    "max_words = 16000\n",
    "max_len = 200\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(final_data)\n",
    "sequences = tokenizer.texts_to_sequences(final_data)\n",
    "tweets = pad_sequences(sequences,maxlen=max_len)\n",
    "with open(\"tokenizer.pickle\",\"wb\") as handle:\n",
    "\tpickle.dump(tokenizer,handle,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print(tweets)\n",
    "\n",
    "\n",
    "dict = {\"Harmful_Traditional_practice\":0,\"Physical_violence\":1,\n",
    "        \"economic_violence\":2,\"emotional_violence\":3,\n",
    "        \"sexual_violence\":4}\n",
    "df[\"labels\"] = \"\"\n",
    "df[\"labels\"] = df[\"type\"].map(dict)\n",
    "labels = df[\"labels\"]\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(tweets,labels,random_state=42)\n",
    "x_train,x_val,y_train,y_val = train_test_split(x_train,y_train,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63a87d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, None, 128)         2048000   \n",
      "                                                                 \n",
      " gru (GRU)                   (None, None, 64)          37248     \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 64)                24960     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,110,533\n",
      "Trainable params: 2,110,533\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
    "\n",
    "def model(y):\n",
    "    x = Embedding(max_words,128)(y)\n",
    "    x = GRU(64,return_sequences=True)(x)\n",
    "    x = GRU(64)(x)\n",
    "    outputs = Dense(5,activation=\"softmax\")(x)\n",
    "    model = Model(y,outputs)\n",
    "    return model\n",
    "\n",
    "model = model(Input(shape=(None,),dtype=\"int32\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8de88b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "697/697 [==============================] - 15s 18ms/step - loss: 0.1347 - accuracy: 0.9626 - val_loss: 0.0250 - val_accuracy: 0.9896\n",
      "Epoch 2/4\n",
      "697/697 [==============================] - 12s 17ms/step - loss: 0.0120 - accuracy: 0.9958 - val_loss: 0.0137 - val_accuracy: 0.9953\n",
      "Epoch 3/4\n",
      "697/697 [==============================] - 12s 18ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0086 - val_accuracy: 0.9983\n",
      "Epoch 4/4\n",
      "697/697 [==============================] - 12s 17ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0086 - val_accuracy: 0.9977\n",
      "310/310 - 2s - loss: 0.0114 - accuracy: 0.9973 - 2s/epoch - 7ms/step\n",
      "\n",
      "Test acc: 99.73 %\n",
      "Test loss: 1.14 %\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    model.compile(Adam(),SparseCategoricalCrossentropy(),metrics=[\"accuracy\"])\n",
    "    checkpoint = ModelCheckpoint(\"gbv.h5\",monitor=\"val_accuracy\",save_best_only=True,save_weights_only=False)\n",
    "    model.fit(x_train,y_train,batch_size=32,epochs=4,validation_data=(x_val,y_val),callbacks=[checkpoint])\n",
    "    best = load_model(\"gbv.h5\")\n",
    "    loss,acc = best.evaluate(x_test,y_test,verbose=2)\n",
    "    print(\"\\nTest acc: {:.2f} %\".format(100*acc))\n",
    "    print(\"Test loss: {:.2f} %\".format(100*loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
